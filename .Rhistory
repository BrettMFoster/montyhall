get_last_word <- function( x )
{
words <- strsplit( x, " " )
words <- unlist( words )
last.word <- words[ length(words) ]
return( last.word )
}
#x <- titles[1]  # grab a single title
#x  # "a beginner’s guide to word embedding with gensim wordvec model
#get_first_word( x )
#get_last_word( x )
first.words <- sapply( titles, get_first_word, USE.NAMES=FALSE )
first.words %>%
table() %>%
sort( decreasing=T ) %>%
head( 1 ) %>%
pander()
last.words <- sapply( titles, get_last_word, USE.NAMES=FALSE )
last.words %>%
table() %>%
sort( decreasing=T ) %>%
head( 1 ) %>%
pander()
title.length <- titles %>% strsplit( " " ) %>% sapply( length )
hist( title.length )
plot( factor(title.length), d$claps )
ave <- tapply( d$claps, title.length, median )
ave <- ave[1:20]  # last couple observations are outliers
plot( ave, type="b", pch=19, cex=2,
xlab="Title Word Count",
ylab="Median Clap Score" )
abline( h=seq(20,140,20), lty=2, col="gray80" )
nchar.title <- titles %>% sapply( nchar )
hist( nchar.title, xlim=c(0,125), breaks=200,
main="Number of Characters Per Title")
plot( nchar.title, d$claps,
bty="n", col=gray(0.5,0.2), pch=19, cex=1.5,
xlim=c(0,150),
xlab="Number of Characters", ylab="Clap Score",
main="Performance as a Function of Title Length")
abline( lm(d$claps~nchar.title), lwd=2, col="darkorange" )
# replace all versions of space
# including special styles like
d$title <- gsub("</?[^>]+>", "", d$title)
d$title <- gsub( "<U\\+200A>—<U\\+200A>", "", d$title )
d$title <- gsub( "<U+200A>", "", d$title )
d$title <- gsub( " ", " ", d$title )
d$title <- gsub( "\\s", " ", d$title )
# do not change this chunk
knitr::opts_chunk$set(echo=F, fig.width=6, fig.height=4, warning=F, message=F )
library( dplyr )
library( pander )
library( magrittr )
library(quanteda)
d <- read.csv("C:\\Users\\brett\\Downloads\\medium-data-utf8.csv")
#preview.these <- c("title", "subtitle", "claps", "reading_time", "publication", "date")
#head( d[preview.these] ) %>% pander()
#
# while running chunks interactively
# to see table output.
# This sets it to "html"
# when knitting the file.
s.type="html"
titles <- tolower( d$title ) # convert to lower case
titles <- gsub( "[0-9]", "", titles )  # remove numbers
tokens <- tokens( titles, remove_punct=TRUE )
tokens <- tokens_remove( tokens, stopwords("english") )
tokens <- gsub("[^[:alnum:]]", " ", tokens)
tokens <- tokens[tokens != " "]
t <- table( unlist( tokens ) )
t %>%
sort() %>%
tail( 25 ) %>%
pander()
# words are grouped by titles inside of the list
# [[1]] is from the first title, [[2]] from second, etc
strsplit( head( titles, 3 ), " " )
get_first_word <- function( x )
{
words <- strsplit( x, " " )
words <- unlist( words )
first.word <- words[1]
return( first.word )
}
get_last_word <- function( x )
{
words <- strsplit( x, " " )
words <- unlist( words )
last.word <- words[ length(words) ]
return( last.word )
}
#x <- titles[1]  # grab a single title
#x  # "a beginner’s guide to word embedding with gensim wordvec model
#get_first_word( x )
#get_last_word( x )
first.words <- sapply( titles, get_first_word, USE.NAMES=FALSE )
first.words %>%
table() %>%
sort( decreasing=T ) %>%
head( 1 ) %>%
pander()
last.words <- sapply( titles, get_last_word, USE.NAMES=FALSE )
last.words %>%
table() %>%
sort( decreasing=T ) %>%
head( 1 ) %>%
pander()
title.length <- titles %>% strsplit( " " ) %>% sapply( length )
hist( title.length )
plot( factor(title.length), d$claps )
ave <- tapply( d$claps, title.length, median )
ave <- ave[1:20]  # last couple observations are outliers
plot( ave, type="b", pch=19, cex=2,
xlab="Title Word Count",
ylab="Median Clap Score" )
abline( h=seq(20,140,20), lty=2, col="gray80" )
nchar.title <- titles %>% sapply( nchar )
hist( nchar.title, xlim=c(0,125), breaks=200,
main="Number of Characters Per Title")
plot( nchar.title, d$claps,
bty="n", col=gray(0.5,0.2), pch=19, cex=1.5,
xlim=c(0,150),
xlab="Number of Characters", ylab="Clap Score",
main="Performance as a Function of Title Length")
abline( lm(d$claps~nchar.title), lwd=2, col="darkorange" )
# replace all versions of space
# including special styles like
d$title <- gsub("</?[^>]+>", "", d$title)
d$title <- gsub( "<U\\+200A>—<U\\+200A>", "", d$title )
d$title <- gsub( "<U+200A>", "", d$title )
d$title <- gsub( " ", " ", d$title )
d$title <- gsub( "\\s", " ", d$title )
d$title <- gsub( "</strong>", "", d$title )
# replace all versions of space
# including special styles like
d$title <- gsub("</?[^>]+>", "", d$title)
d$title <- gsub( "<U\\+200A>—<U\\+200A>", "", d$title )
d$title <- gsub( "<U+200A>", "", d$title )
d$title <- gsub( " ", " ", d$title )
d$title <- gsub( "\\s", " ", d$title )
d$title <- gsub( "</strong>", "", d$title )
d$title <- gsub( "<strong class="markup--strong markup--h3-strong">", "", d$title )
# replace all versions of space
# including special styles like
d$title <- gsub("</?[^>]+>", "", d$title)
d$title <- gsub( "<U\\+200A>—<U\\+200A>", "", d$title )
d$title <- gsub( "<U+200A>", "", d$title )
d$title <- gsub( " ", " ", d$title )
d$title <- gsub( "\\s", " ", d$title )
d$title <- gsub( "</strong>", "", d$title )
d$title <- gsub( "<strong class='markup--strong markup--h3-strong'>", "", d$title )
d$title
titles
# replace all versions of space
# including special styles like
d$title <- gsub("</?[^>]+>", "", d$title)
d$title <- gsub( "<U\\+200A>—<U\\+200A>", "", d$title )
d$title <- gsub( "<U+200A>", "", d$title ),
# replace all versions of space
# including special styles like
d$title <- gsub("</?[^>]+>", "", d$title)
d$title <- gsub( "<U\\+200A>—<U\\+200A>", "", d$title ),
# replace all versions of space
# including special styles like
d$title <- gsub("</?[^>]+>", "", d$title),
# replace all versions of space
# including special styles like
d$title <- gsub("</?[^>]+>", "", d$title)
d$title <- gsub( "<U\\+200A>—<U\\+200A>", "", d$title )
d$title <- gsub( "<U+200A>", "", d$title )
d$title <- gsub( "<u+a>—<u+a>", "", d$title )
d$title <- gsub( " ", " ", d$title )
d$title <- gsub( "\\s", " ", d$title )
d$title <- gsub( "</strong>", "", d$title),
# do not change this chunk
knitr::opts_chunk$set(echo=F, fig.width=6, fig.height=4, warning=F, message=F )
library( dplyr )
library( pander )
library( magrittr )
library(quanteda)
d <- read.csv("C:\\Users\\brett\\Downloads\\medium-data-utf8.csv")
#preview.these <- c("title", "subtitle", "claps", "reading_time", "publication", "date")
#head( d[preview.these] ) %>% pander()
#
# while running chunks interactively
# to see table output.
# This sets it to "html"
# when knitting the file.
s.type="html"
titles <- tolower( d$title ) # convert to lower case
titles <- gsub( "[0-9]", "", titles )  # remove numbers
titles
tokens <- tokens( titles, remove_punct=TRUE )
tokens <- tokens_remove( tokens, stopwords("english") )
tokens <- gsub("[^[:alnum:]]", " ", tokens)
tokens <- tokens[tokens != " "]
t <- table( unlist( tokens ) )
t %>%
sort() %>%
tail( 25 ) %>%
pander()
# words are grouped by titles inside of the list
# [[1]] is from the first title, [[2]] from second, etc
strsplit( head( titles, 3 ), " " )
get_first_word <- function( x )
{
words <- strsplit( x, " " )
words <- unlist( words )
first.word <- words[1]
return( first.word )
}
get_last_word <- function( x )
{
words <- strsplit( x, " " )
words <- unlist( words )
last.word <- words[ length(words) ]
return( last.word )
}
#x <- titles[1]  # grab a single title
#x  # "a beginner’s guide to word embedding with gensim wordvec model
#get_first_word( x )
#get_last_word( x )
first.words <- sapply( titles, get_first_word, USE.NAMES=FALSE )
first.words %>%
table() %>%
sort( decreasing=T ) %>%
head( 1 ) %>%
pander()
last.words <- sapply( titles, get_last_word, USE.NAMES=FALSE )
last.words %>%
table() %>%
sort( decreasing=T ) %>%
head( 1 ) %>%
pander()
title.length <- titles %>% strsplit( " " ) %>% sapply( length )
hist( title.length )
plot( factor(title.length), d$claps )
ave <- tapply( d$claps, title.length, median )
ave <- ave[1:20]  # last couple observations are outliers
plot( ave, type="b", pch=19, cex=2,
xlab="Title Word Count",
ylab="Median Clap Score" )
abline( h=seq(20,140,20), lty=2, col="gray80" )
nchar.title <- titles %>% sapply( nchar )
hist( nchar.title, xlim=c(0,125), breaks=200,
main="Number of Characters Per Title")
plot( nchar.title, d$claps,
bty="n", col=gray(0.5,0.2), pch=19, cex=1.5,
xlim=c(0,150),
xlab="Number of Characters", ylab="Clap Score",
main="Performance as a Function of Title Length")
abline( lm(d$claps~nchar.title), lwd=2, col="darkorange" )
# replace all versions of space
# including special styles like
d$title <- gsub("</?[^>]+>", "", d$title)
d$title <- gsub( "<U\\+200A>—<U\\+200A>", "", d$title )
d$title <- gsub( "<U+200A>", "", d$title )
d$title <- gsub( "<u+a>—<u+a>", "", d$title )
d$title <- gsub( " ", " ", d$title )
d$title <- gsub( "\\s", " ", d$title )
d$title <- gsub( "</strong>", "", d$title)
d$title <- gsub( "<strong class='markup--strong markup--h3-strong'>", "", d$title )
d$title <- gsub( "<strong class=\'markup--strong markup--h-strong\'>", "", d$title )
pat = "^[0-9]{1,2} |^one |^two |^three |^four |^five |^six |^seven |^eight |^nine |^ten "
ht = "^how to "
cl = ": "
ql = "\\?$"
power.list <- grepl( pat, d$title, ignore.case=TRUE )
how.to <- grepl( ht, d$title, ignore.case=TRUE )
colon.list <- grepl( cl, d$title, ignore.case=TRUE )
question.list <- grepl( ql, d$title, ignore.case=TRUE )
other.list <- ! ( power.list | how.to | colon.list | question.list )
title
d$title
titles <- tolower( d$title ) # convert to lower case
titles <- gsub( "[0-9]", "", titles )  # remove numbers
titles
tokens <- tokens( titles, remove_punct=TRUE )
tokens <- tokens_remove( tokens, stopwords("english") )
tokens <- gsub("[^[:alnum:]]", " ", tokens)
tokens <- tokens[tokens != " "]
t <- table( unlist( tokens ) )
t %>%
sort() %>%
tail( 25 ) %>%
pander()
# replace all versions of space
# including special styles like
d$title <- gsub("</?[^>]+>", "", d$title)
d$title <- gsub( "<U\\+200A>—<U\\+200A>", "", d$title )
d$title <- gsub( "<U+200A>", "", d$title )
d$title <- gsub( "<u+a>—<u+a>", "", d$title )
d$title <- gsub( " ", " ", d$title )
d$title <- gsub( "\\s", " ", d$title )
d$title <- gsub( "</strong>", "", d$title)
d$title <- gsub( "<strong class='markup--strong markup--h3-strong'>", "", d$title )
d$title <- gsub( "<strong class=\"""markup--strong markup--h-strong\""">", "", d$title )
# replace all versions of space
# including special styles like
d$title <- gsub("</?[^>]+>", "", d$title)
d$title <- gsub( "<U\\+200A>—<U\\+200A>", "", d$title )
d$title <- gsub( "<U+200A>", "", d$title )
d$title <- gsub( "<u+a>—<u+a>", "", d$title )
d$title <- gsub( " ", " ", d$title )
d$title <- gsub( "\\s", " ", d$title )
d$title <- gsub( "</strong>", "", d$title)
d$title <- gsub( "<strong class=", "", d$title )
d$title <- gsub( "markup--strong markup--h3-strong", "", d$title )
d$title <- gsub( "markup--strong markup--h-strong\", "", d$title )
# replace all versions of space
# including special styles like
d$title <- gsub("</?[^>]+>", "", d$title)
d$title <- gsub( "<U\\+200A>—<U\\+200A>", "", d$title )
d$title <- gsub( "<U+200A>", "", d$title )
d$title <- gsub( "<u+a>—<u+a>", "", d$title )
d$title <- gsub( " ", " ", d$title )
d$title <- gsub( "\\s", " ", d$title )
d$title <- gsub( "</strong>", "", d$title)
d$title <- gsub( "<strong class=", "", d$title )
d$title <- gsub( "markup--strong markup--h3-strong", "", d$title )
d$title <- gsub( "markup--strong markup--h-strong\", "", d$title)
# replace all versions of space
# including special styles like
d$title <- gsub("</?[^>]+>", "", d$title)
d$title <- gsub( "<U\\+200A>—<U\\+200A>", "", d$title )
d$title <- gsub( "<U+200A>", "", d$title )
d$title <- gsub( "<u+a>—<u+a>", "", d$title )
d$title <- gsub( " ", " ", d$title )
d$title <- gsub( "\\s", " ", d$title )
d$title <- gsub( "</strong>", "", d$title)
d$title <- gsub( "<strong class=", "", d$title )
d$title <- gsub( "markup--strong markup--h3-strong", "", d$title )
d$title <- gsub( "markup--strong markup--h-strong", "", d$title)
# do not change this chunk
knitr::opts_chunk$set(echo=F, fig.width=6, fig.height=4, warning=F, message=F )
library( dplyr )
library( pander )
library( magrittr )
library(quanteda)
d <- read.csv("C:\\Users\\brett\\Downloads\\medium-data-utf8.csv")
#preview.these <- c("title", "subtitle", "claps", "reading_time", "publication", "date")
#head( d[preview.these] ) %>% pander()
#
# while running chunks interactively
# to see table output.
# This sets it to "html"
# when knitting the file.
s.type="html"
titles <- tolower( d$title ) # convert to lower case
titles <- gsub( "[0-9]", "", titles )  # remove numbers
titles
tokens <- tokens( titles, remove_punct=TRUE )
tokens <- tokens_remove( tokens, stopwords("english") )
tokens <- gsub("[^[:alnum:]]", " ", tokens)
tokens <- tokens[tokens != " "]
t <- table( unlist( tokens ) )
t %>%
sort() %>%
tail( 25 ) %>%
pander()
# words are grouped by titles inside of the list
# [[1]] is from the first title, [[2]] from second, etc
strsplit( head( titles, 3 ), " " )
get_first_word <- function( x )
{
words <- strsplit( x, " " )
words <- unlist( words )
first.word <- words[1]
return( first.word )
}
get_last_word <- function( x )
{
words <- strsplit( x, " " )
words <- unlist( words )
last.word <- words[ length(words) ]
return( last.word )
}
#x <- titles[1]  # grab a single title
#x  # "a beginner’s guide to word embedding with gensim wordvec model
#get_first_word( x )
#get_last_word( x )
first.words <- sapply( titles, get_first_word, USE.NAMES=FALSE )
first.words %>%
table() %>%
sort( decreasing=T ) %>%
head( 1 ) %>%
pander()
last.words <- sapply( titles, get_last_word, USE.NAMES=FALSE )
last.words %>%
table() %>%
sort( decreasing=T ) %>%
head( 1 ) %>%
pander()
title.length <- titles %>% strsplit( " " ) %>% sapply( length )
hist( title.length )
plot( factor(title.length), d$claps )
ave <- tapply( d$claps, title.length, median )
ave <- ave[1:20]  # last couple observations are outliers
plot( ave, type="b", pch=19, cex=2,
xlab="Title Word Count",
ylab="Median Clap Score" )
abline( h=seq(20,140,20), lty=2, col="gray80" )
nchar.title <- titles %>% sapply( nchar )
hist( nchar.title, xlim=c(0,125), breaks=200,
main="Number of Characters Per Title")
plot( nchar.title, d$claps,
bty="n", col=gray(0.5,0.2), pch=19, cex=1.5,
xlim=c(0,150),
xlab="Number of Characters", ylab="Clap Score",
main="Performance as a Function of Title Length")
abline( lm(d$claps~nchar.title), lwd=2, col="darkorange" )
# do not change this chunk
knitr::opts_chunk$set(echo=F, fig.width=6, fig.height=4, warning=F, message=F )
library( dplyr )
library( pander )
library( magrittr )
library(quanteda)
d <- read.csv("C:\\Users\\brett\\Downloads\\medium-data-utf8.csv")
#preview.these <- c("title", "subtitle", "claps", "reading_time", "publication", "date")
#head( d[preview.these] ) %>% pander()
#
# while running chunks interactively
# to see table output.
# This sets it to "html"
# when knitting the file.
s.type="html"
titles <- tolower( dat ) # convert to lower case
# do not change this chunk
knitr::opts_chunk$set(echo=F, fig.width=6, fig.height=4, warning=F, message=F )
library( dplyr )
library( pander )
library( magrittr )
library(quanteda)
d <- read.csv("C:\\Users\\brett\\Downloads\\medium-data-utf8.csv")
#preview.these <- c("title", "subtitle", "claps", "reading_time", "publication", "date")
#head( d[preview.these] ) %>% pander()
#
# while running chunks interactively
# to see table output.
# This sets it to "html"
# when knitting the file.
s.type="html"
titles <- tolower( df ) # convert to lower case
d$title <- gsub("</?[^>]+>", "", d$title)
d$title <- gsub( "<U\\+200A>—<U\\+200A>", "", d$title )
d$title <- gsub( "<U+200A>", "", d$title )
d$title <- gsub( "<u+a>—<u+a>", "", d$title )
d$title <- gsub( " ", " ", d$title )
d$title <- gsub( "\\s", " ", d$title )
d$title <- gsub( "</strong>", "", d$title)
d$title <- gsub( "<strong class=", "", d$title )
d$title <- gsub( "markup--strong markup--h3-strong", "", d$title )
d$title <- gsub( "markup--strong markup--h-strong", "", d$title)
df <- d$title
titles <- tolower( df ) # convert to lower case
titles <- gsub( "[0-9]", "", titles )  # remove numbers
titles
tokens <- tokens( titles, remove_punct=TRUE )
tokens <- tokens_remove( tokens, stopwords("english") )
tokens <- gsub("[^[:alnum:]]", " ", tokens)
tokens <- tokens[tokens != " "]
t <- table( unlist( tokens ) )
t %>%
sort() %>%
tail( 25 ) %>%
pander()
d$title <- gsub("</?[^>]+>", "", d$title)
d$title <- gsub( "<U\\+200A>—<U\\+200A>", "", d$title )
d$title <- gsub( "<U+200A>", "", d$title )
d$title <- gsub( "<u+a>—<u+a>", "", d$title )
d$title <- gsub( " ", " ", d$title )
d$title <- gsub( "\\s", " ", d$title )
d$title <- gsub( "</strong>", "", d$title)
d$title <- gsub( "<strong class=", "", d$title )
d$title <- gsub( "markup--strong markup--h3-strong", "", d$title )
d$title <- gsub( "markup--strong markup--h-strong", "", d$title)
df <- d$title
titles <- tolower( df ) # convert to lower case
titles <- gsub( "[0-9]", "", titles )  # remove numbers
tokens <- tokens( titles, remove_punct=TRUE )
tokens <- tokens_remove( tokens, stopwords("english") )
tokens <- gsub("[^[:alnum:]]", " ", tokens)
tokens <- tokens[tokens != " "]
t <- table( unlist( tokens ) )
t %>%
sort() %>%
tail( 25 ) %>%
pander()
detach( "package:montyhall" )  # closes the package so not locked
setwd( ".." )  # move up one level with two periods
getwd()        # should be /documents NOT /montyhall
devtools::install( "montyhall" )
setwd( "C:/Users/brett/OneDrive/Desktop/MontyHall" )  # move up one level with two periods
getwd()        # should be /documents NOT /montyhall
devtools::install( "montyhall" )
create_game()
setwd( "C:/Users/brett/OneDrive/Desktop/MontyHall/MontyHall" )  # move up one level with two periods
getwd()        # should be /documents NOT /montyhall
devtools::install( "montyhall" )
setwd( "montyhall" )  # move up one level with two periods
setwd( "montyhall" )  # move up one level with two periods
setwd( "montyhall" )  # move up one level with two periods
setwd( "montyhall" )  # move up one level with two periods
setwd( "montyhall" )  # move up one level with two periods
library(montyhall)
setwd( "C:/Users/brett/OneDrive/Desktop/MontyHall/montyhall" )
setwd( ".." )  # move up one level with two periods
getwd()        # should be /documents NOT /montyhall
devtools::install( "montyhall" )
library( montyhall )
setwd( "montyhall" )
devtools::document()
